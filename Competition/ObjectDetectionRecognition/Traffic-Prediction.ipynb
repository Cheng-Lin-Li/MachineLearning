{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Prediction\n",
    "## Given 20 months Date time, ID of junctions, and number of Vehicles to predict number of vehicles in next 4 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'train.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-41ff9acc366c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m train = pd.read_csv('train.csv', encoding = \"utf-8\", parse_dates=[\"DateTime\"],\n\u001b[1;32m----> 2\u001b[1;33m date_parser=lambda x: pd.to_datetime(x, format=\"%Y-%m-%d %H:%M:%S\"))\n\u001b[0m\u001b[0;32m      3\u001b[0m test = pd.read_csv('test.csv', encoding = \"utf-8\", parse_dates=[\"DateTime\"],\n\u001b[0;32m      4\u001b[0m date_parser=lambda x: pd.to_datetime(x, format=\"%Y-%m-%d %H:%M:%S\"))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1050\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'train.csv' does not exist"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', encoding = \"utf-8\", parse_dates=[\"DateTime\"],\n",
    "date_parser=lambda x: pd.to_datetime(x, format=\"%Y-%m-%d %H:%M:%S\"))\n",
    "test = pd.read_csv('test.csv', encoding = \"utf-8\", parse_dates=[\"DateTime\"],\n",
    "date_parser=lambda x: pd.to_datetime(x, format=\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-54efa6b8693a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Junction</th>\n",
       "      <th>Vehicles</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48115</th>\n",
       "      <td>2017-06-30 19:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>20170630194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48116</th>\n",
       "      <td>2017-06-30 20:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>20170630204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48117</th>\n",
       "      <td>2017-06-30 21:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>20170630214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48118</th>\n",
       "      <td>2017-06-30 22:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>20170630224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48119</th>\n",
       "      <td>2017-06-30 23:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>20170630234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DateTime  Junction  Vehicles           ID\n",
       "48115 2017-06-30 19:00:00         4        11  20170630194\n",
       "48116 2017-06-30 20:00:00         4        30  20170630204\n",
       "48117 2017-06-30 21:00:00         4        16  20170630214\n",
       "48118 2017-06-30 22:00:00         4        22  20170630224\n",
       "48119 2017-06-30 23:00:00         4        12  20170630234"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split DateTime to year, quarter, month, hour to make more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Junction</th>\n",
       "      <th>Vehicles</th>\n",
       "      <th>ID</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>20151101001</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>20151101011</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-11-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>20151101021</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-11-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20151101031</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>20151101041</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateTime  Junction  Vehicles           ID  year  quarter  month  \\\n",
       "0 2015-11-01 00:00:00         1        15  20151101001  2015        4     11   \n",
       "1 2015-11-01 01:00:00         1        13  20151101011  2015        4     11   \n",
       "2 2015-11-01 02:00:00         1        10  20151101021  2015        4     11   \n",
       "3 2015-11-01 03:00:00         1         7  20151101031  2015        4     11   \n",
       "4 2015-11-01 04:00:00         1         9  20151101041  2015        4     11   \n",
       "\n",
       "   hour  \n",
       "0     0  \n",
       "1     1  \n",
       "2     2  \n",
       "3     3  \n",
       "4     4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['year'] = train['DateTime'].dt.year\n",
    "train['quarter'] = train['DateTime'].dt.quarter\n",
    "train['month'] = train['DateTime'].dt.month\n",
    "train['hour'] = train['DateTime'].dt.hour\n",
    "\n",
    "train.head(5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Junction</th>\n",
       "      <th>ID</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-07-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>20170701001</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-07-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>20170701011</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-07-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>20170701021</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-07-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>20170701031</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-07-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>20170701041</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateTime  Junction           ID  year  quarter  month  hour\n",
       "0 2017-07-01 00:00:00         1  20170701001  2017        3      7     0\n",
       "1 2017-07-01 01:00:00         1  20170701011  2017        3      7     1\n",
       "2 2017-07-01 02:00:00         1  20170701021  2017        3      7     2\n",
       "3 2017-07-01 03:00:00         1  20170701031  2017        3      7     3\n",
       "4 2017-07-01 04:00:00         1  20170701041  2017        3      7     4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['year'] = test['DateTime'].dt.year\n",
    "test['quarter'] = test['DateTime'].dt.quarter\n",
    "test['month'] = test['DateTime'].dt.month\n",
    "test['hour'] = test['DateTime'].dt.hour\n",
    "\n",
    "test.head(5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data for training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train[['year','quarter', 'month', 'hour','Junction']]\n",
    "y = train['Vehicles']\n",
    "X_test = test[['year','quarter', 'month', 'hour','Junction']]\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X, y, test_size = 0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>Junction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41605</th>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5461</th>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14844</th>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38253</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7745</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  quarter  month  hour  Junction\n",
       "41605  2017        2      4    13         3\n",
       "5461   2016        2      6    13         1\n",
       "14844  2015        4     11    12         2\n",
       "38253  2016        4     11    21         3\n",
       "7745   2016        3      9    17         1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## standardization\n",
    "### Due to year 2017 included in test set, so include year into the scope of standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mmc = MinMaxScaler(feature_range=(0,1)) # default (0, 1) for sigmoid function\n",
    "mmc.fit(X_train)\n",
    "X_train_std = mmc.transform(X_train)\n",
    "X_validate_std = mmc.transform(X_validate)\n",
    "X_test_std = mmc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.33333333, 0.27272727, 0.56521739, 0.66666667],\n",
       "       [0.5       , 0.33333333, 0.45454545, 0.56521739, 0.        ],\n",
       "       [0.        , 1.        , 0.90909091, 0.52173913, 0.33333333],\n",
       "       ...,\n",
       "       [1.        , 0.        , 0.18181818, 1.        , 0.        ],\n",
       "       [1.        , 0.33333333, 0.45454545, 0.47826087, 0.        ],\n",
       "       [0.5       , 1.        , 0.90909091, 0.34782609, 0.66666667]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a based line model: SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# C and gamma are the parameters of SVR with kernel='rbf'\n",
    "# Below statement does not work and reason unknow. The main issue is the data of y_train.\n",
    "\n",
    "# C_range = np.logspace(2, 10, 13)\n",
    "# gamma_range = np.logspace(0.1, 3, 13)\n",
    "# param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "# cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "# grid = GridSearchCV(svm.SVR(), param_grid=param_grid, cv=cv)\n",
    "# grid.fit(X_train_std, , y_train.values.ravel())\n",
    "\n",
    "# print(\"The best parameters are %s with a score of %0.2f\"\n",
    "#       % (grid.best_params_, grid.best_score_))\n",
    "\n",
    "# Bigger C takes longer time but better prediction. Be aware of overfitting.\n",
    "clf = svm.SVR(C=20000)\n",
    "clf.fit(X_train_std, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_validate_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_validate, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print ('rmse=%f'%rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'ID' : pd.Series(test['ID']),\n",
    "      'Vehicles' : pd.Series(y_pred)\n",
    "    }\n",
    "df = pd.DataFrame(d)\n",
    "df['Vehicles'] = df['Vehicles'].astype(int)\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model: Try NN, LSTM, GRU, Convolutional LSTM for this prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, TimeDistributed, LSTM, GRU, ConvLSTM2D\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "\n",
    "def create_NN_model(optimizer='adam', init='normal'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=5, activation='relu', kernel_initializer=init))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer=init))\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer=init))\n",
    "    model.add(Dense(1, activation='relu', kernel_initializer=init))\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "s_optimizer = 'adam' # rmsprop or adam\n",
    "s_init='uniform'\n",
    "n_epoches = 5\n",
    "n_batch_size = 6\n",
    "\n",
    "model_NN = create_NN_model(optimizer=s_optimizer, init=s_init)\n",
    "model_NN.fit(X_train_std, y_train.values.ravel(),\n",
    "          epochs=n_epoches,\n",
    "          batch_size=n_batch_size,\n",
    "          callbacks=[EarlyStopping(monitor='acc', min_delta=0.001, patience=2, verbose=1, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_NN.predict(X_validate_std, batch_size=n_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_validate, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print ('rmse=%f'%rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_result = model_NN.predict(X_test_std, batch_size=n_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'ID' : pd.Series(test['ID']),\n",
    "      'Vehicles' : pd.Series(y_result.ravel())\n",
    "    }\n",
    "df = pd.DataFrame(d)\n",
    "df['Vehicles'] = df['Vehicles'].astype(int)\n",
    "df.to_csv('submission-nn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN model auto tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# grid search epochs, batch size and optimizer\n",
    "# optimizers = ['rmsprop', 'adam']\n",
    "# init = ['glorot_uniform', 'normal', 'uniform']\n",
    "# epochs = [5, 10]\n",
    "# batches = [6, 12, 24]\n",
    "\n",
    "optimizers = ['adam']\n",
    "init = ['glorot_uniform', 'uniform', 'normal']\n",
    "epochs = [3]\n",
    "batches = [6]\n",
    "\n",
    "# create model\n",
    "model_NN = KerasRegressor(build_fn=create_NN_model, verbose=0)\n",
    "#Best: 0.091082 using {'batch_size': 6, 'epochs': 10, 'init': 'uniform', 'optimizer': 'adam'}\n",
    "\n",
    "param_grid = dict(optimizer=optimizers, epochs=epochs, batch_size=batches, init=init)\n",
    "grid = GridSearchCV(estimator=model_NN, param_grid=param_grid)\n",
    "grid_result = grid.fit(X_train_std, y_train.values.ravel())\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
    "## No state of LSTM\n",
    "### stateful = False\n",
    "### If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.\n",
    "##  If you want to keep state memory of LSTM with Time windows approach (lags, horizon). You cannot shuffle your data.\n",
    "## If you want to control the state of LSTM\n",
    "\n",
    "### stateful = True, and change your training epochs to external loop. below example epochs = 100\n",
    "```python\n",
    "for i in range(100):\n",
    "\tmodel.fit(trainX, trainY, epochs=1, batch_size=batch_size, verbose=2, shuffle=False)\n",
    "\tmodel.reset_states()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LSTM_model(optimizer='adam', init='normal'):\n",
    "    model = Sequential()\n",
    "    # batch_input_shape=(batch, timesteps/lags, features)\n",
    "    # input_shape=(timesteps/lags, features)\n",
    "    model.add(LSTM(512, input_shape=(1, 5), return_sequences=True, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, \n",
    "                   kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros',\n",
    "                   unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, \n",
    "                   activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, \n",
    "                   dropout=0.0, recurrent_dropout=0.0, implementation=1, return_state=False, \n",
    "                   go_backwards=False, stateful=False, unroll=False))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(LSTM(256, return_sequences=True, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_state=False, go_backwards=False, stateful=False, unroll=False))\n",
    "    # The last layer of LSTM, return_sequences = False\n",
    "    model.add(LSTM(64, return_state=False, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, go_backwards=False, stateful=False, unroll=False))\n",
    "    model.add(Dense(1, activation='relu', kernel_initializer=init))\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "s_optimizer = 'adam' # rmsprop or adam\n",
    "s_init='uniform'\n",
    "n_epoches = 5\n",
    "n_batch_size = 6\n",
    "\n",
    "# if timesteps/lags = 1\n",
    "X_3D_train_std = X_train_std.reshape(X_train_std.shape[0],1, X_train_std.shape[1])\n",
    "\n",
    "model_LSTM = create_LSTM_model(optimizer=s_optimizer, init=s_init)\n",
    "model_LSTM.fit(X_3D_train_std, y_train.values.ravel(),\n",
    "          epochs=n_epoches,\n",
    "          batch_size=n_batch_size,\n",
    "          callbacks=[EarlyStopping(monitor='acc', min_delta=0.001, patience=2, verbose=1, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_LSTM.predict(X_validate_std.reshape(X_validate_std.shape[0],1, X_validate_std.shape[1]), batch_size=n_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_validate, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print ('rmse=%f'%rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_result = model_LSTM.predict(X_test_std.reshape(X_test_std.shape[0],1, X_test_std.shape[1]), batch_size=n_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'ID' : pd.Series(test['ID']),\n",
    "      'Vehicles' : pd.Series(y_result.ravel())\n",
    "    }\n",
    "df = pd.DataFrame(d)\n",
    "df['Vehicles'] = df['Vehicles'].astype(int)\n",
    "df.to_csv('submission-lstm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# grid search epochs, batch size and optimizer\n",
    "# optimizers = ['rmsprop', 'adam']\n",
    "# init = ['glorot_uniform', 'normal', 'uniform']\n",
    "# epochs = [10, 20, 50]\n",
    "# batches = [5, 10, 20]\n",
    "\n",
    "optimizers = ['adam']\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = [3]\n",
    "batches = [6]\n",
    "\n",
    "# create model\n",
    "model_LSTM = KerasRegressor(build_fn=create_LSTM_model, verbose=0)\n",
    "\n",
    "param_grid = dict(optimizer=optimizers, epochs=epochs, batch_size=batches, init=init)\n",
    "grid = GridSearchCV(estimator=model_LSTM, param_grid=param_grid)\n",
    "grid_result = grid.fit(X_3D_train_std, y_train.values.ravel())\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_GRU_model(optimizer='adam', init='normal'):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(512, input_shape=(1, 5), return_sequences=True, activation='tanh', \n",
    "                  recurrent_activation='hard_sigmoid', use_bias=True, \n",
    "                  kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', \n",
    "                  kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, \n",
    "                  activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, \n",
    "                  dropout=0.0, recurrent_dropout=0.0, implementation=1, return_state=False, \n",
    "                  go_backwards=False, stateful=False, unroll=False))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(GRU(256, return_sequences=True, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_state=False, go_backwards=False, stateful=False, unroll=False))\n",
    "    model.add(GRU(64, return_sequences=False, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_state=False, go_backwards=False, stateful=False, unroll=False))\n",
    "    model.add(Dense(1, activation='relu', kernel_initializer=init))\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "s_optimizer = 'adam' # rmsprop or adam\n",
    "s_init='uniform'\n",
    "n_epoches = 5\n",
    "n_batch_size = 6\n",
    "\n",
    "# if timesteps/lags = 1\n",
    "X_3D_train_std = X_train_std.reshape(X_train_std.shape[0],1, X_train_std.shape[1])\n",
    "\n",
    "model_GRU = create_GRU_model(optimizer=s_optimizer, init=s_init)\n",
    "model_GRU.fit(X_3D_train_std, y_train.values.ravel(),\n",
    "          epochs=n_epoches,\n",
    "          batch_size=n_batch_size,\n",
    "          callbacks=[EarlyStopping(monitor='acc', min_delta=0.001, patience=2, verbose=1, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_GRU.predict(X_validate_std.reshape(X_validate_std.shape[0],1, X_validate_std.shape[1]), batch_size=n_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_validate, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print ('rmse=%f'%rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_result = model_GRU.predict(X_test_std.reshape(X_test_std.shape[0],1, X_test_std.shape[1]), batch_size=n_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'ID' : pd.Series(test['ID']),\n",
    "      'Vehicles' : pd.Series(y_result.ravel())\n",
    "    }\n",
    "df = pd.DataFrame(d)\n",
    "df['Vehicles'] = df['Vehicles'].astype(int)\n",
    "df.to_csv('submission-gru.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# grid search epochs, batch size and optimizer\n",
    "# optimizers = ['rmsprop', 'adam']\n",
    "# init = ['glorot_uniform', 'normal', 'uniform']\n",
    "# epochs = [10, 20, 50]\n",
    "# batches = [5, 10, 20]\n",
    "\n",
    "optimizers = ['adam']\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = [3]\n",
    "batches = [6]\n",
    "\n",
    "# create model\n",
    "model = KerasRegressor(build_fn=create_GRU_model, verbose=0)\n",
    "\n",
    "param_grid = dict(optimizer=optimizers, epochs=epochs, batch_size=batches, init=init)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X_3D_train_std, y_train.values.ravel())\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ConvLSTM2D_model(optimizer='adam', init='normal'):\n",
    "    model = Sequential()\n",
    "    model.add(ConvLSTM2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, \n",
    "                         dilation_rate=(1, 1), activation='tanh', recurrent_activation='hard_sigmoid', \n",
    "                         use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', \n",
    "                         bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, \n",
    "                         recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, \n",
    "                         kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, \n",
    "                         return_sequences=False, go_backwards=False, stateful=False, dropout=0.0, \n",
    "                         recurrent_dropout=0.0))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(ConvLSTM2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, return_sequences=False, go_backwards=False, stateful=False, dropout=0.0, recurrent_dropout=0.0))\n",
    "    model.add(ConvLSTM2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, return_sequences=False, go_backwards=False, stateful=False, dropout=0.0, recurrent_dropout=0.0))\n",
    "    model.add(Dense(1, activation='softmax', kernel_initializer=init))\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
